{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rg6hMnlC3tdi"
   },
   "source": [
    "<img src=\"https://unlearning-challenge.github.io/Unlearning-logo.png\" width=\"100px\">\n",
    "\n",
    "# NeurIPS 2023 Machine Unlearning Challenge Starting Kit\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unlearning-challenge/starting-kit/blob/main/unlearning-CIFAR10.ipynb) [![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/unlearning-challenge/starting-kit/main/unlearning-CIFAR10.ipynb)\n",
    "\n",
    "\n",
    "This notebook is part of the starting kit for the [NeurIPS 2023 Machine Unlearning Challenge](https://unlearning-challenge.github.io/). This notebook explains the pipeline of the challenge and contains sample code to make a submission.\n",
    "\n",
    "\n",
    "This notebook has 3 sections:\n",
    "\n",
    "  * üíæ In the first section we'll load a sample dataset (CIFAR10) and pre-trained model (ResNet18).\n",
    "\n",
    "  * üéØ In the second section we'll develop the unlearning algorithm. We start by splitting the original training set into a retain set and a forget set. The goal of an unlearning algorithm is to update the pre-trained model so that it approximates as much as possible a model that has been trained on the retain set but not on the forget set. We provide a simple unlearning algorithm as a starting point for participants to develop their own unlearning algorithms.\n",
    "\n",
    "  * üèÖ In the third section we'll score our unlearning algorithm using a simple membership inference attacks (MIA).\n",
    "  \n",
    "\n",
    "We emphasize that this notebook is provided for convenience so help participants quickly get started. Submissions will be scored using a different method than the one provided in this notebook on a different (private) dataset of human faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6YXq1oMM3bj",
    "outputId": "beca12f1-b07c-4a46-d2f6-a38b2617fa16"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CF7zXiGLM3bk"
   },
   "source": [
    "# üíæ Download dataset and pre-trained model\n",
    "\n",
    "In this section we'll load a sample dataset (CIFAR10), a pre-trained model (ResNet18), plot some images and compute the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5G7DBCoM3bl",
    "outputId": "cfa5b700-3cdc-4140-978e-5e80de861c0a"
   },
   "outputs": [],
   "source": [
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=normalize\n",
    ")\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Rn6UKX_M3bl"
   },
   "outputs": [],
   "source": [
    "# download pre-trained weights\n",
    "response = requests.get(\n",
    "    \"https://unlearning-challenge.s3.eu-west-1.amazonaws.com/weights_resnet18_cifar10.pth\"\n",
    ")\n",
    "open(\"weights_resnet18_cifar10.pth\", \"wb\").write(response.content)\n",
    "weights_pretrained = torch.load(\"weights_resnet18_cifar10.pth\", map_location=DEVICE)\n",
    "\n",
    "# load pre-trained weights\n",
    "model = resnet18(weights=None, num_classes=10)\n",
    "model.load_state_dict(weights_pretrained)\n",
    "model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0OhF8zu1M3bl"
   },
   "source": [
    "Let us show some of the training images, for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "ASG-8jPEM3bl",
    "outputId": "c963af8c-7bd7-46c6-cf92-a731e3343411"
   },
   "outputs": [],
   "source": [
    "# a temporary data loader without normalization, just to show the images\n",
    "tmp_dl = DataLoader(\n",
    "    torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
    "    ),\n",
    "    batch_size=16 * 5,\n",
    ")\n",
    "images, labels = next(iter(tmp_dl))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plt.title(\"Sample images from CIFAR10 dataset\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cZWK7sDSatvj"
   },
   "source": [
    "We'll now compute the model's accuracy on the train and test set. This model has been trained without data augmentation, so generalization accuracy is lower than state-of-the-art models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2hegPagM3bl",
    "outputId": "4d701c22-ec1f-4ac6-9cd5-0855446813de"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for info, loader in zip((\"train\", \"test\"), (train_loader, test_loader)):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        print(f\"{info} set accuracy: {100.0 * correct / total}%%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kXEWkDTTn4iO"
   },
   "source": [
    "# üéØ Unlearning Algorithm\n",
    "\n",
    "In this section we develop the unlearning algorithm.\n",
    "\n",
    "We start by splitting the original training set into a retain set and a forget set. Typically, the retain set is much later than the forget set. Here, we produce a split that is 20% forget set, 80% retain set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_set, retain_set = torch.utils.data.random_split(train_set, [0.2, 0.8])\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=128, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of an unlearning algorithm is to produce a model that approximates as much as possible the model trained solely on the retain set.\n",
    "\n",
    "Below is a simple unlearning algorithms provided for illustration purposes. We call this algorithm `unlearning by fine-tuning`. It starts from the pre-trained and optimizes for a few epochs on the retain set. This is a very simple unlearning algorithm, but it is not very computationally efficient. \n",
    "\n",
    "To make a new entry in the competitions, participants will submit an unlearning function with the same API as the one below. Note that the unlearning function takes as input the pre-trained model, the retain set, the forget set and the test set (even though the fine-tuning algorithm below only uses the retain set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvLkBLisM3bm"
   },
   "outputs": [],
   "source": [
    "def unlearning(net, retain, forget, test):\n",
    "    \"\"\"Unlearning by fine-tuning.\n",
    "\n",
    "    Fine-tuning is a very simple algorithm that trains using only\n",
    "    the retain set.\n",
    "\n",
    "    Args:\n",
    "      net : nn.Module.\n",
    "        pre-trained model to use as base of unlearning.\n",
    "      retain : torch.utils.data.DataLoader.\n",
    "        Dataset loader with the retain set. This is the subset\n",
    "        of the training set that we don't want to forget.  \n",
    "      forget : torch.utils.data.DataLoader.\n",
    "        Dataset loader with the forget set. This is the subset\n",
    "        of the training set that we want to forget.\n",
    "      test : torch.utils.data.DataLoader.\n",
    "        Dataset loader with the test set.\n",
    "    Returns:\n",
    "      net : updated model\n",
    "    \"\"\"\n",
    "    epochs = 20\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for inputs, targets in retain:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o27hc1HOM3bm"
   },
   "outputs": [],
   "source": [
    "model_ft = resnet18(weights=None, num_classes=10)\n",
    "model_ft.load_state_dict(weights_pretrained)\n",
    "model_ft.to(DEVICE)\n",
    "model_ft = unlearning(model_ft, retain_loader, forget_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xccyUQcuM3bl"
   },
   "source": [
    "# üèÖ Evaluation\n",
    "\n",
    "In this section we'll quantify the quality of the unlearning algorithm through a simple membership inference attack (MIA). We provide this simple MIA for convenience, so that participants can quickly obtain a metric for their unlearning algorithm,but submissions will be scored using a different method.\n",
    "\n",
    "This attack consists of a linear model trained to distinguish between samples in the retain set and the forget set from their per-sample loss. We plot below a histogram of these two losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWUxHD3EM3bm"
   },
   "outputs": [],
   "source": [
    "def compute_losses(net, loader):\n",
    "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    all_losses = []\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        logits = net(inputs)\n",
    "        losses = criterion(logits, targets).numpy(force=True)\n",
    "        [all_losses.append(l) for l in losses]\n",
    "\n",
    "    return np.array(all_losses)\n",
    "\n",
    "\n",
    "test_losses = compute_losses(model, test_loader)\n",
    "forget_losses = compute_losses(model, forget_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2t4sYtZM3bm"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Losses on test and forget set\")\n",
    "plt.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"loss on test set\")\n",
    "plt.hist(forget_losses, density=True, alpha=0.5, bins=50, label=\"loss on forget set\")\n",
    "plt.xlim((0, np.max(test_losses)))\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ApxbefWMM3bm"
   },
   "source": [
    "As per the above plot, the distributions of losses are quite different between the forget and retain set. This suggests that the simple MIA that we're considering should be reasonably effective.\n",
    "\n",
    "This MIA is defined below. It takes as input the per-sample losses computed previously and a member label indicating whether the sample is in the retain set or the forget set. It returns the cross-validation accuracy of a linear model trained to distinguish between the two classes. The accuracy here is measured in terms of the F1 score (harmonic mean of precision and recall) since the two classes are often severely imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gBtdz7AM3bm"
   },
   "outputs": [],
   "source": [
    "def simple_mia(sample_loss, members, n_splits=10):\n",
    "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
    "\n",
    "    Args:\n",
    "      sample_loss : array_like of shape (n,).\n",
    "        objective function evaluated on n samples.\n",
    "      members : array_like of shape (n,),\n",
    "        whether a sample was used for training.\n",
    "      n_splits: int\n",
    "        number of splits to use in the cross-validation.\n",
    "    Returns:\n",
    "      score : array_like of size (n_splits,)\n",
    "    \"\"\"\n",
    "\n",
    "    unique_members = np.unique(members)\n",
    "    if not np.all(unique_members == np.array([0, 1])):\n",
    "        raise ValueError(\"members should only have 0 and 1s\")\n",
    "\n",
    "    attack_model = linear_model.LogisticRegression()\n",
    "    cv = model_selection.StratifiedShuffleSplit(n_splits=n_splits)\n",
    "    return model_selection.cross_val_score(\n",
    "        attack_model, sample_loss, members, cv=cv, scoring=\"f1_macro\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekuEyHlUM3bm"
   },
   "outputs": [],
   "source": [
    "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
    "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
    "\n",
    "mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "print(\n",
    "    \"The MIA attack has a macro-F1 accuracy of %.3f on seen vs unseen images\"\n",
    "    % mia_scores.mean()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "12Ek9x4zM3bm"
   },
   "source": [
    "We'll now compute the accuracy of the MIA on the unlearned model. We expect the MIA to be less accurate on the unlearned model than on the original model. This would suggest that the unlearning algorithm has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYgYXRvPM3bm"
   },
   "outputs": [],
   "source": [
    "ft_forget_losses = compute_losses(model_ft, forget_loader)\n",
    "samples_mia_ft = np.concatenate((test_losses, ft_forget_losses)).reshape((-1, 1))\n",
    "labels_mia = [0] * len(test_losses) + [1] * len(ft_forget_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWvzT3cPGvYs"
   },
   "outputs": [],
   "source": [
    "mia_scores_ft = simple_mia(samples_mia_ft, labels_mia)\n",
    "\n",
    "print(\n",
    "    \"The MIA attack has a macro-F1 accuracy of %.3f on seen vs unseen images\"\n",
    "    % mia_scores_ft.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJ8JI-GDM3bn"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.set_title(\"Initial model.\\nAttack accuracy: %s\" % mia_scores.mean())\n",
    "ax1.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"loss on test set\")\n",
    "ax1.hist(forget_losses, density=True, alpha=0.5, bins=50, label=\"loss on forget set\")\n",
    "\n",
    "ax2.set_title(\"Unlearned model.\\nAttack accuracy: %s\" % mia_scores_ft.mean())\n",
    "ax2.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"loss on test set\")\n",
    "ax2.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"loss on forget set\")\n",
    "\n",
    "ax1.set_yscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax1.set_xlim((0, np.max(test_losses)))\n",
    "ax2.set_xlim((0, np.max(test_losses)))\n",
    "plt.legend(frameon=False, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# TODO: add axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_tp4dhvrz5i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
